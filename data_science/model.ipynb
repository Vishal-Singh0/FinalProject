{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            name\n",
      "0   5        John Doe\n",
      "1   6      Jane Smith\n",
      "2   7     Bob Johnson\n",
      "3   8  Alice Williams\n",
      "4   9   Charlie Brown\n",
      "   id                 title  duration    difficulty  rating            domain\n",
      "0   1       Cloud Computing   8 hours      advanced     3.3      Data Science\n",
      "1   2       Web Development  42 hours      beginner     3.7   Web Development\n",
      "2   3  Intro to Programming  31 hours      beginner     1.0  Computer Science\n",
      "3   4       Cloud Computing  84 hours      advanced     1.6  Computer Science\n",
      "4   5       Data Structures  72 hours  intermediate     3.8   Cloud Computing\n",
      "   id  user_id  course_id enrollment_date completion_date\n",
      "0   1       19         90      2024-06-26      2024-07-15\n",
      "1   2        1         58      2024-09-21      2024-09-21\n",
      "2   3       89         47      2024-08-14      2025-01-25\n",
      "3   4       38         55      2023-11-29             NaN\n",
      "4   5       69          3      2024-06-07      2024-07-03\n",
      "   id  user_id  enrollment_id  score grade  progress  certificate_earned\n",
      "0   1       39             15     73     D        24               False\n",
      "1   2       80             92     60     A        92                True\n",
      "2   3       48             44     68     D         2                True\n",
      "3   4       43             72     61     B        34               False\n",
      "4   5       10              3     57     B        66               False\n",
      "   id            domain            title    courses  duration0    difficulty\n",
      "0   1   Web Development  Learning Path 1  1,2,3,4,5         10      beginner\n",
      "1   2      Data Science  Learning Path 2  1,2,3,4,5         10  intermediate\n",
      "2   3  Machine Learning  Learning Path 3      2,3,5         10      advanced\n",
      "3   4     Cybersecurity  Learning Path 4      2,4,5         10      beginner\n",
      "4   5   Cloud Computing  Learning Path 5      1,2,3         10  intermediate\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users_df = pd.read_csv('../data_engineering/staging/transformed_users.csv')\n",
    "courses_df = pd.read_csv('../data_engineering/staging/transformed_courses.csv')\n",
    "enrollments_df = pd.read_csv('../data_engineering/staging/transformed_enrollment.csv')\n",
    "performance_df = pd.read_csv('../data_engineering/staging/transformed_performance.csv')\n",
    "learning_paths_df = pd.read_csv('../data_engineering/staging/transformed_learning_path.csv')\n",
    "\n",
    "print(users_df.head())\n",
    "print(courses_df.head())\n",
    "print(enrollments_df.head())\n",
    "print(performance_df.head())\n",
    "print(learning_paths_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      50 non-null     int64 \n",
      " 1   name    50 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 932.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          100 non-null    int64  \n",
      " 1   title       100 non-null    object \n",
      " 2   duration    100 non-null    object \n",
      " 3   difficulty  100 non-null    object \n",
      " 4   rating      100 non-null    float64\n",
      " 5   domain      100 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               100 non-null    int64 \n",
      " 1   user_id          100 non-null    int64 \n",
      " 2   course_id        100 non-null    int64 \n",
      " 3   enrollment_date  100 non-null    object\n",
      " 4   completion_date  43 non-null     object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  100 non-null    int64 \n",
      " 1   user_id             100 non-null    int64 \n",
      " 2   enrollment_id       100 non-null    int64 \n",
      " 3   score               100 non-null    int64 \n",
      " 4   grade               100 non-null    object\n",
      " 5   progress            100 non-null    int64 \n",
      " 6   certificate_earned  100 non-null    bool  \n",
      "dtypes: bool(1), int64(5), object(1)\n",
      "memory usage: 4.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          50 non-null     int64 \n",
      " 1   domain      50 non-null     object\n",
      " 2   title       50 non-null     object\n",
      " 3   courses     50 non-null     object\n",
      " 4   duration0   50 non-null     int64 \n",
      " 5   difficulty  50 non-null     object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 2.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(users_df.info())\n",
    "print(courses_df.info())\n",
    "print(enrollments_df.info())\n",
    "print(performance_df.info())\n",
    "print(learning_paths_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    0\n",
      "user_id_x             0\n",
      "course_id             0\n",
      "enrollment_date       0\n",
      "completion_date       0\n",
      "user_id_y             0\n",
      "enrollment_id         0\n",
      "score                 0\n",
      "grade                 0\n",
      "progress              0\n",
      "certificate_earned    0\n",
      "dtype: int64\n",
      "id_x             0\n",
      "domain           0\n",
      "title_x          0\n",
      "courses          0\n",
      "duration0        0\n",
      "difficulty_x     0\n",
      "id_y            20\n",
      "title_y         20\n",
      "duration        20\n",
      "difficulty_y    20\n",
      "rating          20\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18488\\3309713558.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  enrollments_df['completion_date'].fillna(pd.to_datetime('today'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "enrollments_df['completion_date'].fillna(pd.to_datetime('today'), inplace=True)\n",
    "\n",
    "user_course_df = pd.merge(enrollments_df, performance_df, on='id', how='left')\n",
    "\n",
    "learning_path_df = pd.merge(learning_paths_df, courses_df, left_on='domain', right_on='domain', how='left')\n",
    "\n",
    "print(user_course_df.isnull().sum())\n",
    "print(learning_path_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_id   1     3    5    6    8    9    10   11   12   15  ...   81   83  \\\n",
      "id                                                            ...             \n",
      "1          0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2          0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3          0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4          0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5          0.0  57.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "course_id   84   85   86   87    90   94   95   99  \n",
      "id                                                  \n",
      "1          0.0  0.0  0.0  0.0  73.0  0.0  0.0  0.0  \n",
      "2          0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  \n",
      "3          0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  \n",
      "4          0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  \n",
      "5          0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "user_path_matrix = user_course_df.pivot_table(index='id', columns='course_id', values='score', fill_value=0)\n",
    "\n",
    "print(user_path_matrix.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4          5          6  \\\n",
      "id                                                                           \n",
      "1   0.003479  0.004599  0.010575  0.064796 -0.036681  -0.042441   0.125935   \n",
      "2   0.018729  0.009734  0.084770  0.253843 -0.357579  -0.114231   0.190195   \n",
      "3   0.018154 -0.010328 -0.083142 -0.437394  0.416443  -0.658820  -0.558614   \n",
      "4  -0.000397 -0.000588 -0.001325  0.002558  0.005361  -0.001338   0.008919   \n",
      "5   0.060046  0.033703 -0.086976 -1.081342 -1.794742  45.420635 -29.338790   \n",
      "\n",
      "            7         8         9  \n",
      "id                                 \n",
      "1   -0.165537 -0.096418  0.299961  \n",
      "2   -0.796799 -0.237165 -0.251318  \n",
      "3    1.043306 -2.964001  2.261585  \n",
      "4   -0.003099  0.010753  0.009421  \n",
      "5   12.608849  6.589204  1.857121  \n",
      "Recommended courses for user 1: [64, 10, 83, 23]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "svd = TruncatedSVD(n_components=10, random_state=42)  \n",
    "matrix = svd.fit_transform(user_path_matrix)\n",
    "\n",
    "reduced_matrix = pd.DataFrame(matrix, index=user_path_matrix.index)\n",
    "print(reduced_matrix.head())\n",
    "\n",
    "\n",
    "def recommend_courses(user_id, num_recommendations=5):\n",
    "    user_idx = user_path_matrix.index.get_loc(user_id)\n",
    "\n",
    "    user_vector = reduced_matrix.iloc[user_idx]\n",
    "\n",
    "    similarities = np.dot(reduced_matrix, user_vector)\n",
    "\n",
    "    similar_users = np.argsort(similarities)[::-1][1:num_recommendations + 1]\n",
    "\n",
    "    recommended_courses = set()\n",
    "    for sim_user in similar_users:\n",
    "        recommended_courses.update(user_path_matrix.columns[(user_path_matrix.iloc[sim_user] > 0)])\n",
    "\n",
    "    return list(recommended_courses)\n",
    "\n",
    "user_id = 1  \n",
    "recommendations = recommend_courses(user_id)\n",
    "print(f\"Recommended courses for user {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0, Recall (Sensitivity): 0.04, Accuracy: 1.0, True Positives: 4, False Negatives: 96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_recommendations(true_courses, recommended_courses):\n",
    "    true_set = set(true_courses)\n",
    "    recommended_set = set(recommended_courses)\n",
    "\n",
    "    tp = len(true_set.intersection(recommended_set)) \n",
    "    fn = len(true_set - recommended_set)  \n",
    "\n",
    "    precision = tp / len(recommended_set) if recommended_set else 0\n",
    "    recall = tp / len(true_set) if true_set else 0\n",
    "    accuracy = tp / len(recommended_set) if recommended_set else 0\n",
    "\n",
    "    return precision, recall, accuracy, tp, fn\n",
    "\n",
    "df = pd.read_csv(\"./staging/transformed_courses.csv\")\n",
    "true_courses = df['id'].tolist() \n",
    "\n",
    "user_id = 1 \n",
    "recommended_courses = recommend_courses(user_id)\n",
    "\n",
    "precision, recall, accuracy, tp, fn = evaluate_recommendations(true_courses, recommended_courses)\n",
    "print(f\"Precision: {precision}, Recall (Sensitivity): {recall}, Accuracy: {accuracy}, True Positives: {tp}, False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components: 5 -> Average Precision: 0.134, Average Recall: 0.44\n",
      "n_components: 10 -> Average Precision: 0.134, Average Recall: 0.44\n",
      "n_components: 15 -> Average Precision: 0.134, Average Recall: 0.44\n",
      "n_components: 20 -> Average Precision: 0.134, Average Recall: 0.44\n",
      "n_components: 25 -> Average Precision: 0.134, Average Recall: 0.44\n",
      "Best n_components: 5 with Precision: 0.134, Recall: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_svd(n_components, interaction_matrix, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(interaction_matrix):\n",
    "        train_data = interaction_matrix.iloc[train_index]\n",
    "        test_data = interaction_matrix.iloc[test_index]\n",
    "\n",
    "        svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "        train_matrix = svd.fit_transform(train_data)\n",
    "\n",
    "        reduced_train_matrix = pd.DataFrame(train_matrix, index=train_data.index)\n",
    "\n",
    "        for user_id in test_data.index:\n",
    "            true_courses = test_data.columns[(test_data.loc[user_id] > 0)].tolist()\n",
    "            recommendations = recommend_courses(user_id)  \n",
    "\n",
    "            precision, recall = evaluate_recommendations(true_courses, recommendations)\n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "\n",
    "    avg_precision = np.mean(precision_scores)\n",
    "    avg_recall = np.mean(recall_scores)\n",
    "\n",
    "    return avg_precision, avg_recall\n",
    "\n",
    "component_range = [5, 10, 15, 20, 25]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n in component_range:\n",
    "    avg_precision, avg_recall = evaluate_svd(n, user_path_matrix)\n",
    "    results[n] = (avg_precision, avg_recall)\n",
    "    print(f\"n_components: {n} -> Average Precision: {avg_precision}, Average Recall: {avg_recall}\")\n",
    "\n",
    "best_n = max(results, key=lambda x: results[x][0]) \n",
    "print(f\"Best n_components: {best_n} with Precision: {results[best_n][0]}, Recall: {results[best_n][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recommendation System KPIs ---\n",
      "+--------------------------+---------+\n",
      "| Metric                   | Value   |\n",
      "+==========================+=========+\n",
      "| Precision                | 1.00    |\n",
      "+--------------------------+---------+\n",
      "| Recall (Sensitivity)     | 0.04    |\n",
      "+--------------------------+---------+\n",
      "| F1 Score                 | 0.08    |\n",
      "+--------------------------+---------+\n",
      "| Engagement Rate          | 4.00%   |\n",
      "+--------------------------+---------+\n",
      "| Click-Through Rate (CTR) | 4.00%   |\n",
      "+--------------------------+---------+\n",
      "| Course Completion Rate   | 100.00% |\n",
      "+--------------------------+---------+\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_kpis(true_courses, recommended_courses):\n",
    "    true_set = set(true_courses)\n",
    "    recommended_set = set(recommended_courses)\n",
    "\n",
    "    tp = len(true_set.intersection(recommended_set))  \n",
    "    fp = len(recommended_set - true_set)             \n",
    "    fn = len(true_set - recommended_set)              \n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_user_engagement(recommended_courses, total_users):\n",
    "    engaged_users = len(set(recommended_courses)) \n",
    "    engagement_rate = (engaged_users / total_users) * 100 if total_users > 0 else 0\n",
    "    return engagement_rate\n",
    "\n",
    "def calculate_ctr(recommended_courses, total_recommendations_shown):\n",
    "    clicks = len(set(recommended_courses))  \n",
    "    ctr = (clicks / total_recommendations_shown) * 100 if total_recommendations_shown > 0 else 0\n",
    "    return ctr\n",
    "\n",
    "def calculate_completion_rate(true_courses, recommended_courses):\n",
    "    true_set = set(true_courses)\n",
    "    recommended_set = set(recommended_courses)\n",
    "    \n",
    "    completed_courses = len(true_set.intersection(recommended_set))  \n",
    "    completion_rate = (completed_courses / len(recommended_courses)) * 100 if len(recommended_courses) > 0 else 0\n",
    "    return completion_rate\n",
    "\n",
    "def display_kpis(precision, recall, f1_score, engagement_rate, ctr, completion_rate):\n",
    "\n",
    "    kpi_data = [\n",
    "        [\"Precision\", f\"{precision:.2f}\"],\n",
    "        [\"Recall (Sensitivity)\", f\"{recall:.2f}\"],\n",
    "        [\"F1 Score\", f\"{f1_score:.2f}\"],\n",
    "        [\"Engagement Rate\", f\"{engagement_rate:.2f}%\"],\n",
    "        [\"Click-Through Rate (CTR)\", f\"{ctr:.2f}%\"],\n",
    "        [\"Course Completion Rate\", f\"{completion_rate:.2f}%\"]\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n--- Recommendation System KPIs ---\")\n",
    "    print(tabulate(kpi_data, headers=[\"Metric\", \"Value\"], tablefmt=\"grid\"))\n",
    "    print(\"-----------------------------------\\n\")\n",
    "df = pd.read_csv(\"../data_engineering/staging/transformed_courses.csv\")\n",
    "true_courses = df['id'].tolist() \n",
    "\n",
    "user_id = 1 \n",
    "recommended_courses = recommend_courses(user_id)\n",
    "\n",
    "precision, recall, f1_score = calculate_kpis(true_courses, recommended_courses)\n",
    "total_users = len(true_courses)  \n",
    "total_recommendations_shown = 100\n",
    "\n",
    "engagement_rate = calculate_user_engagement(recommended_courses, total_users)\n",
    "ctr = calculate_ctr(recommended_courses, total_recommendations_shown)\n",
    "completion_rate = calculate_completion_rate(true_courses, recommended_courses)\n",
    "\n",
    "display_kpis(precision, recall, f1_score, engagement_rate, ctr, completion_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
